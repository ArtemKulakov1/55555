import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.datasets import make_moons

# ===============================
# 1. Custom dataset generation
# ===============================
# Створимо dataset з двома класами, який нелінійно розділяється
X, y = make_moons(n_samples=300, noise=0.2, random_state=42)

# Розділимо на train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ===============================
# 2. Моделі
# ===============================
models = {
    "Decision Tree": DecisionTreeClassifier(max_depth=5, random_state=42),
    "KNN (k=5)": KNeighborsClassifier(n_neighbors=5),
    "SVM Linear": SVC(kernel='linear', C=1),
    "SVM RBF": SVC(kernel='rbf', C=1, gamma='scale')
}

# ===============================
# 3. Функція для візуалізації рішень
# ===============================
def plot_decision_boundary(model, X, y, ax, title):
    h = 0.02
    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    ax.contourf(xx, yy, Z, alpha=0.3)
    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, edgecolor='k', cmap=plt.cm.coolwarm)
    ax.set_title(title)

# ===============================
# 4. Навчання та візуалізація
# ===============================
fig, axes = plt.subplots(2, 2, figsize=(12,10))

for ax, (name, model) in zip(axes.ravel(), models.items()):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    plot_decision_boundary(model, X, y, ax, f"{name}\nAccuracy: {acc:.2f}")

plt.tight_layout()
plt.show()


